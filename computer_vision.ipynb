{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries\n",
    "\n",
    "`torchvision.datasets` contains some popular datasets for computer vision.\n",
    "\n",
    "`torchvision.models` contains some popular architectures for computer vision.\n",
    "\n",
    "`torchvision.transforms` contains common image transformations.\n",
    "\n",
    "`torch.utils.data.Dataset` is an abstract class representing a dataset.\n",
    "\n",
    "`torch.utils.data.DataLoader` wraps a dataset and provides access to the underlying data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.1\n",
      "0.15.2\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(torch.__version__)\n",
    "print(torchvision.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "train_data = datasets.FashionMNIST(root=\"data\", train=True, download=True, transform=ToTensor(), target_transform=None)\n",
    "test_data = datasets.FashionMNIST(root=\"data\", train=False, download=True, transform=ToTensor(), target_transform=None)\n",
    "\n",
    "print(len(train_data))\n",
    "print(len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n"
     ]
    }
   ],
   "source": [
    "class_names = train_data.classes\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'T-shirt/top': 0, 'Trouser': 1, 'Pullover': 2, 'Dress': 3, 'Coat': 4, 'Sandal': 5, 'Shirt': 6, 'Sneaker': 7, 'Bag': 8, 'Ankle boot': 9}\n"
     ]
    }
   ],
   "source": [
    "class_to_idx = train_data.class_to_idx\n",
    "print(class_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.0000, 0.0510,\n",
       "           0.2863, 0.0000, 0.0000, 0.0039, 0.0157, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0039, 0.0039, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0118, 0.0000, 0.1412, 0.5333,\n",
       "           0.4980, 0.2431, 0.2118, 0.0000, 0.0000, 0.0000, 0.0039, 0.0118,\n",
       "           0.0157, 0.0000, 0.0000, 0.0118],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0235, 0.0000, 0.4000, 0.8000,\n",
       "           0.6902, 0.5255, 0.5647, 0.4824, 0.0902, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0471, 0.0392, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6078, 0.9255,\n",
       "           0.8118, 0.6980, 0.4196, 0.6118, 0.6314, 0.4275, 0.2510, 0.0902,\n",
       "           0.3020, 0.5098, 0.2824, 0.0588],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.2706, 0.8118, 0.8745,\n",
       "           0.8549, 0.8471, 0.8471, 0.6392, 0.4980, 0.4745, 0.4784, 0.5725,\n",
       "           0.5529, 0.3451, 0.6745, 0.2588],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0039, 0.0039, 0.0039, 0.0000, 0.7843, 0.9098, 0.9098,\n",
       "           0.9137, 0.8980, 0.8745, 0.8745, 0.8431, 0.8353, 0.6431, 0.4980,\n",
       "           0.4824, 0.7686, 0.8980, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7176, 0.8824, 0.8471,\n",
       "           0.8745, 0.8941, 0.9216, 0.8902, 0.8784, 0.8706, 0.8784, 0.8667,\n",
       "           0.8745, 0.9608, 0.6784, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7569, 0.8941, 0.8549,\n",
       "           0.8353, 0.7765, 0.7059, 0.8314, 0.8235, 0.8275, 0.8353, 0.8745,\n",
       "           0.8627, 0.9529, 0.7922, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0039, 0.0118, 0.0000, 0.0471, 0.8588, 0.8627, 0.8314,\n",
       "           0.8549, 0.7529, 0.6627, 0.8902, 0.8157, 0.8549, 0.8784, 0.8314,\n",
       "           0.8863, 0.7725, 0.8196, 0.2039],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0235, 0.0000, 0.3882, 0.9569, 0.8706, 0.8627,\n",
       "           0.8549, 0.7961, 0.7765, 0.8667, 0.8431, 0.8353, 0.8706, 0.8627,\n",
       "           0.9608, 0.4667, 0.6549, 0.2196],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0157, 0.0000, 0.0000, 0.2157, 0.9255, 0.8941, 0.9020,\n",
       "           0.8941, 0.9412, 0.9098, 0.8353, 0.8549, 0.8745, 0.9176, 0.8510,\n",
       "           0.8510, 0.8196, 0.3608, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0039, 0.0157, 0.0235, 0.0275, 0.0078, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.9294, 0.8863, 0.8510, 0.8745,\n",
       "           0.8706, 0.8588, 0.8706, 0.8667, 0.8471, 0.8745, 0.8980, 0.8431,\n",
       "           0.8549, 1.0000, 0.3020, 0.0000],\n",
       "          [0.0000, 0.0118, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.2431, 0.5686, 0.8000, 0.8941, 0.8118, 0.8353, 0.8667,\n",
       "           0.8549, 0.8157, 0.8275, 0.8549, 0.8784, 0.8745, 0.8588, 0.8431,\n",
       "           0.8784, 0.9569, 0.6235, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0706, 0.1725, 0.3216, 0.4196,\n",
       "           0.7412, 0.8941, 0.8627, 0.8706, 0.8510, 0.8863, 0.7843, 0.8039,\n",
       "           0.8275, 0.9020, 0.8784, 0.9176, 0.6902, 0.7373, 0.9804, 0.9725,\n",
       "           0.9137, 0.9333, 0.8431, 0.0000],\n",
       "          [0.0000, 0.2235, 0.7333, 0.8157, 0.8784, 0.8667, 0.8784, 0.8157,\n",
       "           0.8000, 0.8392, 0.8157, 0.8196, 0.7843, 0.6235, 0.9608, 0.7569,\n",
       "           0.8078, 0.8745, 1.0000, 1.0000, 0.8667, 0.9176, 0.8667, 0.8275,\n",
       "           0.8627, 0.9098, 0.9647, 0.0000],\n",
       "          [0.0118, 0.7922, 0.8941, 0.8784, 0.8667, 0.8275, 0.8275, 0.8392,\n",
       "           0.8039, 0.8039, 0.8039, 0.8627, 0.9412, 0.3137, 0.5882, 1.0000,\n",
       "           0.8980, 0.8667, 0.7373, 0.6039, 0.7490, 0.8235, 0.8000, 0.8196,\n",
       "           0.8706, 0.8941, 0.8824, 0.0000],\n",
       "          [0.3843, 0.9137, 0.7765, 0.8235, 0.8706, 0.8980, 0.8980, 0.9176,\n",
       "           0.9765, 0.8627, 0.7608, 0.8431, 0.8510, 0.9451, 0.2549, 0.2863,\n",
       "           0.4157, 0.4588, 0.6588, 0.8588, 0.8667, 0.8431, 0.8510, 0.8745,\n",
       "           0.8745, 0.8784, 0.8980, 0.1137],\n",
       "          [0.2941, 0.8000, 0.8314, 0.8000, 0.7569, 0.8039, 0.8275, 0.8824,\n",
       "           0.8471, 0.7255, 0.7725, 0.8078, 0.7765, 0.8353, 0.9412, 0.7647,\n",
       "           0.8902, 0.9608, 0.9373, 0.8745, 0.8549, 0.8314, 0.8196, 0.8706,\n",
       "           0.8627, 0.8667, 0.9020, 0.2627],\n",
       "          [0.1882, 0.7961, 0.7176, 0.7608, 0.8353, 0.7725, 0.7255, 0.7451,\n",
       "           0.7608, 0.7529, 0.7922, 0.8392, 0.8588, 0.8667, 0.8627, 0.9255,\n",
       "           0.8824, 0.8471, 0.7804, 0.8078, 0.7294, 0.7098, 0.6941, 0.6745,\n",
       "           0.7098, 0.8039, 0.8078, 0.4510],\n",
       "          [0.0000, 0.4784, 0.8588, 0.7569, 0.7020, 0.6706, 0.7176, 0.7686,\n",
       "           0.8000, 0.8235, 0.8353, 0.8118, 0.8275, 0.8235, 0.7843, 0.7686,\n",
       "           0.7608, 0.7490, 0.7647, 0.7490, 0.7765, 0.7529, 0.6902, 0.6118,\n",
       "           0.6549, 0.6941, 0.8235, 0.3608],\n",
       "          [0.0000, 0.0000, 0.2902, 0.7412, 0.8314, 0.7490, 0.6863, 0.6745,\n",
       "           0.6863, 0.7098, 0.7255, 0.7373, 0.7412, 0.7373, 0.7569, 0.7765,\n",
       "           0.8000, 0.8196, 0.8235, 0.8235, 0.8275, 0.7373, 0.7373, 0.7608,\n",
       "           0.7529, 0.8471, 0.6667, 0.0000],\n",
       "          [0.0078, 0.0000, 0.0000, 0.0000, 0.2588, 0.7843, 0.8706, 0.9294,\n",
       "           0.9373, 0.9490, 0.9647, 0.9529, 0.9569, 0.8667, 0.8627, 0.7569,\n",
       "           0.7490, 0.7020, 0.7137, 0.7137, 0.7098, 0.6902, 0.6510, 0.6588,\n",
       "           0.3882, 0.2275, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1569,\n",
       "           0.2392, 0.1725, 0.2824, 0.1608, 0.1373, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000]]]),\n",
       " 9)"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image, label = train_data[0]\n",
    "image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 28, 28]), 9)"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.shape, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x179aeabd0>"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGdCAYAAABU0qcqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAgHklEQVR4nO3dfWyV9f3G8ast7aHF9pRS+wSFFUSYAjWi1EZFlAboMiLKFlCzgHEwWTFDxiRdVHQP6X64OKNh+M8GmohPiUA0C0ZRypwUA0IYcVZoulFSWpTYFgq0pef+/UHsVnny++X0fE7L+5WchJ5zrt7f3r3L1bvnnM9JCIIgEAAAMZZovQAAwJWJAgIAmKCAAAAmKCAAgAkKCABgggICAJiggAAAJiggAICJQdYL+LZIJKLGxkalp6crISHBejkAAEdBEOj48eMqKChQYuKFz3PiroAaGxtVWFhovQwAwGVqaGjQiBEjLnh73BVQenq69RIQZ8aOHeuc+eMf/+i1rU2bNjln9u3b55zp7Ox0znR1dTlnrrvuOueMJP3whz90ztTX1ztnnn/+eedMa2urcwY2LvX/eZ8V0Jo1a/TMM8+oqalJxcXFeuGFFzRlypRL5viz23/57IuBONovKSnJOTNkyBCvbaWkpDhnfNbnk4lEIs6Z5ORk54wkpaWlOWcGDx7snOHnfWC71Pe3T56E8Prrr2v58uVatWqVPv30UxUXF2vmzJk6evRoX2wOANAP9UkBPfvss1q0aJEefPBBXXfddXrxxReVlpamv/71r32xOQBAPxT1Aurs7NTu3btVVlb2340kJqqsrEw7duw45/4dHR1qa2vrdQEADHxRL6CvvvpK3d3dys3N7XV9bm6umpqazrl/VVWVwuFwz4VnwAHAlcH8haiVlZVqbW3tuTQ0NFgvCQAQA1F/Flx2draSkpLU3Nzc6/rm5mbl5eWdc/9QKKRQKBTtZQAA4lzUz4BSUlI0efJkbd26tee6SCSirVu3qrS0NNqbAwD0U33yOqDly5drwYIFuummmzRlyhQ999xzam9v14MPPtgXmwMA9EN9UkDz5s3Tl19+qSeffFJNTU264YYbtGXLlnOemAAAuHIlBHH20vm2tjaFw2HrZVzUQJtQcMMNN3jl5s+f75yZO3euc6a7u9s54zsJITU11TkzbNgwr23Fsy+++MI54zOpYdy4cc6Zbz++/F28++67zhnJb6TT/v37vbY1ELW2tiojI+OCt5s/Cw4AcGWigAAAJiggAIAJCggAYIICAgCYoIAAACYoIACACQoIAGCCAgIAmKCAAAAmKCAAgAkKCABggmGkcexiQ/wu5OWXX3bOTJo0yTkjSYmJ7r+/HD9+3Dlz+vRp50xXV5dzRvIbfJqcnOyc8TnG29vbnTM+A0Kl+B6eO3jwYOeMz5BZ6ez7m7n6+9//7pz5yU9+4pzpDxhGCgCISxQQAMAEBQQAMEEBAQBMUEAAABMUEADABAUEADBBAQEATFBAAAATFBAAwAQFBAAwQQEBAExQQAAAE4OsF4ALe+utt5wzo0aNcs4cPXrUOSP5TVoeNMj9kDtz5oxzJiEhwTkj+a3PZ1tfffWVcyYpKck548tn0nmsnDp1yjnjM1Fd8psKPnXqVOfM+PHjnTOff/65cybexO9RBgAY0CggAIAJCggAYIICAgCYoIAAACYoIACACQoIAGCCAgIAmKCAAAAmKCAAgAkKCABgggICAJhgGGmMTJ482TnjM1jUZ8ilzwBOyW845uDBg50zw4cPd86kpaU5ZyS/IZxdXV3OGZ993t3d7ZzxHcqanJzsnPEZGnv8+HHnzOHDh50zPmvz5fN9+ulPf+qcWbFihXMm3nAGBAAwQQEBAExQQAAAExQQAMAEBQQAMEEBAQBMUEAAABMUEADABAUEADBBAQEATFBAAAATFBAAwATDSGPkzjvvdM6EQqGYZCKRiHNG8htG2tHR4ZxZuXKlc6axsdE5I/kNuiwoKHDOHDlyxDnjMyi1s7PTOSP5HUdXXXWVc+bGG290zjzyyCPOGZ8hvZLf0Fifn6cf/ehHzhmGkQIA4IkCAgCYiHoBPfXUU0pISOh1GT9+fLQ3AwDo5/rkMaDrr79e77///n834vmGZwCAgatPmmHQoEHKy8vri08NABgg+uQxoAMHDqigoECjR4/WAw88oEOHDl3wvh0dHWpra+t1AQAMfFEvoJKSEq1fv15btmzR2rVrVV9fr9tvv/2C7/1eVVWlcDjccyksLIz2kgAAcSjqBVReXq4f//jHmjRpkmbOnKm//e1vamlp0RtvvHHe+1dWVqq1tbXn0tDQEO0lAQDiUJ8/OyAzM1PXXnutDh48eN7bQ6GQ14veAAD9W5+/DujEiROqq6tTfn5+X28KANCPRL2AVqxYoerqav373//Wxx9/rHvuuUdJSUm67777or0pAEA/FvU/wR0+fFj33Xefjh07pquvvlq33XabampqdPXVV0d7UwCAfiwhCILAehH/q62tTeFw2HoZUVdTU+OcycnJcc5c6NmGF+M7sNJn+GRra6tz5pZbbnHOzJgxwzkjScOHD3fOrFu3zjnzs5/9zDmzf/9+50xqaqpzRvIbNNvc3Oyc2bt3r3PmwIEDzhmfnwtJGjx4sHPmzJkzzhmfaTETJkxwzkjSF1984ZXz0draqoyMjAveziw4AIAJCggAYIICAgCYoIAAACYoIACACQoIAGCCAgIAmKCAAAAmKCAAgAkKCABgggICAJiggAAAJvr8DelwVnFxsXPG591hExPdf6eI5RsCXmwwYTRt2bLFK9fe3u6cue6665wzK1ascM5s3LjROTN79mznjCQNGuT+X8Onn37qnJk8ebJzxmfY55AhQ5wzktTd3e2ciUQizplDhw45Z0pLS50zUmyHkV4KZ0AAABMUEADABAUEADBBAQEATFBAAAATFBAAwAQFBAAwQQEBAExQQAAAExQQAMAEBQQAMEEBAQBMUEAAABNMw/YwYcIE58yXX37pnPGZ+puUlOScSUhIcM5IUmpqqnPm2LFjXtty5fM9kqSOjg7nTH5+vnPm97//vXPG5/vU1dXlnPHdlu90ZleNjY3OmeHDh3ttK1bTsE+dOuWcuf32250zkvTSSy955foCZ0AAABMUEADABAUEADBBAQEATFBAAAATFBAAwAQFBAAwQQEBAExQQAAAExQQAMAEBQQAMEEBAQBMMIzUw8qVK50zPoM7T5w44ZzxGZ7oszZJOn36tHPGZ8DqTTfd5JwZNmyYc0aSsrKynDPJycnOmdzcXOeMz2BRn++RJKWkpDhnMjMznTPz5s1zzgwdOtQ54zPsU5LC4XBMtuWzv31+LuINZ0AAABMUEADABAUEADBBAQEATFBAAAATFBAAwAQFBAAwQQEBAExQQAAAExQQAMAEBQQAMEEBAQBMMIzUw8cff+ycycvLc85cc801zpmMjAznzJAhQ5wzknTgwAHnjM+w1JqaGudMJBJxzvjmfL6mpKQk58ygQe4/rgkJCc4Zye9rSkx0/332+PHjzpkvvvjCOZOWluackfy+Tz77obGx0TmzadMm50y84QwIAGCCAgIAmHAuoO3bt2v27NkqKChQQkLCOaeBQRDoySefVH5+vlJTU1VWVub1pxoAwMDmXEDt7e0qLi7WmjVrznv76tWr9fzzz+vFF1/Uzp07NWTIEM2cOdP7jbEAAAOT86Oa5eXlKi8vP+9tQRDoueee0+OPP667775bkvTyyy8rNzdXmzZt0vz58y9vtQCAASOqjwHV19erqalJZWVlPdeFw2GVlJRox44d5810dHSora2t1wUAMPBFtYCampoknft+97m5uT23fVtVVZXC4XDPpbCwMJpLAgDEKfNnwVVWVqq1tbXn0tDQYL0kAEAMRLWAvnmxZXNzc6/rm5ubL/hCzFAopIyMjF4XAMDAF9UCKioqUl5enrZu3dpzXVtbm3bu3KnS0tJobgoA0M85PwvuxIkTOnjwYM/H9fX12rt3r7KysjRy5EgtW7ZMv/vd7zR27FgVFRXpiSeeUEFBgebMmRPNdQMA+jnnAtq1a5fuvPPOno+XL18uSVqwYIHWr1+vxx57TO3t7Vq8eLFaWlp02223acuWLRo8eHD0Vg0A6PcSgiAIrBfxv9ra2hQOh62XEReGDh3qnBk7dqxzZsmSJc4ZSbrjjjucMz5PMvE5HlpaWpwzkpScnOyc8RlYGe98hpj6DOH0eYG6z/Hwz3/+0zkjSQ888IBXDme1trZe9HF982fBAQCuTBQQAMAEBQQAMEEBAQBMUEAAABMUEADABAUEADBBAQEATFBAAAATFBAAwAQFBAAwQQEBAExQQAAAE85vx4DY+frrr50zn3zyiXOmo6PDOSNJd911l3PGZ/h6SkqKc2bIkCHOGclvsnUkEvHaliufCdU+GcnvawqFQs6Zzs5O54zPW7t8/PHHzhn0Pc6AAAAmKCAAgAkKCABgggICAJiggAAAJiggAIAJCggAYIICAgCYoIAAACYoIACACQoIAGCCAgIAmGAYaYz4DIVMTk52zvgMd/QZECpJbW1tzhmfYZ/d3d3OGd+vyYfP9zaW64tnPseDj5aWlphsR4rdQNuBcAxxBgQAMEEBAQBMUEAAABMUEADABAUEADBBAQEATFBAAAATFBAAwAQFBAAwQQEBAExQQAAAExQQAMAEw0hjxGdwYFdXVx+s5Fx1dXVeOZ9hpIMGuR9yPgNWffl8n+J5GKnP2nz5fJ98Bu768DlWfSUmuv9e7zNwdyDgDAgAYIICAgCYoIAAACYoIACACQoIAGCCAgIAmKCAAAAmKCAAgAkKCABgggICAJiggAAAJiggAIAJhpHGsVgNNTx16pRzRvIbPhkKhZwzZ86ccc74DD2VYjdY1Gc7PhmfY0jy+5o6OjqcM2lpac4Zn/3gcwyh73EGBAAwQQEBAEw4F9D27ds1e/ZsFRQUKCEhQZs2bep1+8KFC5WQkNDrMmvWrGitFwAwQDgXUHt7u4qLi7VmzZoL3mfWrFk6cuRIz+XVV1+9rEUCAAYe50dqy8vLVV5eftH7hEIh5eXleS8KADDw9cljQNu2bVNOTo7GjRunJUuW6NixYxe8b0dHh9ra2npdAAADX9QLaNasWXr55Ze1detW/d///Z+qq6tVXl5+wacHV1VVKRwO91wKCwujvSQAQByK+uuA5s+f3/PviRMnatKkSRozZoy2bdum6dOnn3P/yspKLV++vOfjtrY2SggArgB9/jTs0aNHKzs7WwcPHjzv7aFQSBkZGb0uAICBr88L6PDhwzp27Jjy8/P7elMAgH7E+U9wJ06c6HU2U19fr7179yorK0tZWVl6+umnNXfuXOXl5amurk6PPfaYrrnmGs2cOTOqCwcA9G/OBbRr1y7deeedPR9/8/jNggULtHbtWu3bt08vvfSSWlpaVFBQoBkzZui3v/2t1wwwAMDA5VxA06ZNu+igwnffffeyFoT/8hkI6SMSiXjlfAaf+nxNPhnfIZw+fPZfUlJSH6zkXD6DOyW//efzffLZd7Fam69Ybqu/YxYcAMAEBQQAMEEBAQBMUEAAABMUEADABAUEADBBAQEATFBAAAATFBAAwAQFBAAwQQEBAExQQAAAExQQAMBE1N+SG1eO4cOHO2e+/vpr54zP5GjficQ+k5Z9J04PND77rquryznjs79jNX0cbjgDAgCYoIAAACYoIACACQoIAGCCAgIAmKCAAAAmKCAAgAkKCABgggICAJiggAAAJiggAIAJCggAYIJhpHHMd6BmrJw5cyYm20lJSXHOdHd3e23LZ9BlrDI+x4PvoNRIJOKcSU5Ods50dHQ4Z3z2g8/afMX7z2084QwIAGCCAgIAmKCAAAAmKCAAgAkKCABgggICAJiggAAAJiggAIAJCggAYIICAgCYoIAAACYoIACACYaRwpvPIMmkpCTnjM/QU5/tSH5DOH2GT/qsr7Oz0znjOxhz0CD3/xp8tnXy5EnnjI/MzMyYbAduOAMCAJiggAAAJiggAIAJCggAYIICAgCYoIAAACYoIACACQoIAGCCAgIAmKCAAAAmKCAAgAkKCABggmGk8OYzuDNWEhISvHK+wztdJSa6/+7n+zX58NkPPuvz2Y7PcNrU1FTnjK9YHUMDAWdAAAATFBAAwIRTAVVVVenmm29Wenq6cnJyNGfOHNXW1va6z+nTp1VRUaFhw4bpqquu0ty5c9Xc3BzVRQMA+j+nAqqurlZFRYVqamr03nvvqaurSzNmzFB7e3vPfR599FG9/fbbevPNN1VdXa3Gxkbde++9UV84AKB/c3oSwpYtW3p9vH79euXk5Gj37t2aOnWqWltb9Ze//EUbNmzQXXfdJUlat26dvv/976umpka33HJL9FYOAOjXLusxoNbWVklSVlaWJGn37t3q6upSWVlZz33Gjx+vkSNHaseOHef9HB0dHWpra+t1AQAMfN4FFIlEtGzZMt16662aMGGCJKmpqUkpKSnnvP96bm6umpqazvt5qqqqFA6Hey6FhYW+SwIA9CPeBVRRUaH9+/frtddeu6wFVFZWqrW1tefS0NBwWZ8PANA/eL0QdenSpXrnnXe0fft2jRgxouf6vLw8dXZ2qqWlpddZUHNzs/Ly8s77uUKhkEKhkM8yAAD9mNMZUBAEWrp0qTZu3KgPPvhARUVFvW6fPHmykpOTtXXr1p7ramtrdejQIZWWlkZnxQCAAcHpDKiiokIbNmzQ5s2blZ6e3vO4TjgcVmpqqsLhsB566CEtX75cWVlZysjI0COPPKLS0lKeAQcA6MWpgNauXStJmjZtWq/r161bp4ULF0qS/vSnPykxMVFz585VR0eHZs6cqT//+c9RWSwAYOBwKqDvMmRv8ODBWrNmjdasWeO9KPQPPgM1YyXeB0IOxGGkPl9TrIaRpqWlOWfQ9+L3fxAAwIBGAQEATFBAAAATFBAAwAQFBAAwQQEBAExQQAAAExQQAMAEBQQAMEEBAQBMUEAAABMUEADABAUEADDh9Y6oiI14n+jsIykpyXoJF+Wzz2M1pTqW+y5Wx57PBO3u7m7nTLwfd1cqzoAAACYoIACACQoIAGCCAgIAmKCAAAAmKCAAgAkKCABgggICAJiggAAAJiggAIAJCggAYIICAgCYYBhpHPMZchnLAaadnZ3OmbS0tD5YSfREIhHnjM+gyzNnzjhn4v14iJV4H0Y6EPd5X+EMCABgggICAJiggAAAJiggAIAJCggAYIICAgCYoIAAACYoIACACQoIAGCCAgIAmKCAAAAmKCAAgAmGkSKmEhPdf+fxGT7pM7hT8ltfrDI+g1J994MPnyGcPvvBRyyHkeK74wwIAGCCAgIAmKCAAAAmKCAAgAkKCABgggICAJiggAAAJiggAIAJCggAYIICAgCYoIAAACYoIACACYaRxjGf4Y6x1NjY6Jy59tprnTNnzpxxzvgM7vTNJScnx2Q7PhnfY8hnAOygQbH578Tna4rlMNJ4/7mNJ5wBAQBMUEAAABNOBVRVVaWbb75Z6enpysnJ0Zw5c1RbW9vrPtOmTVNCQkKvy8MPPxzVRQMA+j+nAqqurlZFRYVqamr03nvvqaurSzNmzFB7e3uv+y1atEhHjhzpuaxevTqqiwYA9H9Ojxpu2bKl18fr169XTk6Odu/eralTp/Zcn5aWpry8vOisEAAwIF3WY0Ctra2SpKysrF7Xv/LKK8rOztaECRNUWVmpkydPXvBzdHR0qK2trdcFADDweT9vMhKJaNmyZbr11ls1YcKEnuvvv/9+jRo1SgUFBdq3b59Wrlyp2tpavfXWW+f9PFVVVXr66ad9lwEA6Ke8C6iiokL79+/XRx991Ov6xYsX9/x74sSJys/P1/Tp01VXV6cxY8ac83kqKyu1fPnyno/b2tpUWFjouywAQD/hVUBLly7VO++8o+3bt2vEiBEXvW9JSYkk6eDBg+ctoFAopFAo5LMMAEA/5lRAQRDokUce0caNG7Vt2zYVFRVdMrN3715JUn5+vtcCAQADk1MBVVRUaMOGDdq8ebPS09PV1NQkSQqHw0pNTVVdXZ02bNigH/zgBxo2bJj27dunRx99VFOnTtWkSZP65AsAAPRPTgW0du1aSWdfbPq/1q1bp4ULFyolJUXvv/++nnvuObW3t6uwsFBz587V448/HrUFAwAGBuc/wV1MYWGhqqurL2tBAIArA9Ow4S0zM9M5M2TIEOeMz5Tl7Oxs54wkJSa6vzTOJ+MzQTuWfKZh+0ycbmhocM6kpaU5Z873BKi+4nM8+E5v7+8YRgoAMEEBAQBMUEAAABMUEADABAUEADBBAQEATFBAAAATFBAAwAQFBAAwQQEBAExQQAAAExQQAMAEw0jjWEJCgnPmUhPLo2nPnj3Omc8++8w509LS4pyJ5bBPn+GTJ06ccM74fG99jiFJOnPmjHPGZ6BmZ2enc2bo0KHOmU8++cQ54+tKHSzqgzMgAIAJCggAYIICAgCYoIAAACYoIACACQoIAGCCAgIAmKCAAAAmKCAAgAkKCABgggICAJiIu1lwsZxlFu/ifV+cPn3aOeMzJ8tnO93d3c4ZXz6z4Do6OpwzzII7y+d46Orqcs7g8l3qmE0I4ux/ucOHD6uwsNB6GQCAy9TQ0KARI0Zc8Pa4K6BIJKLGxkalp6ef89tbW1ubCgsL1dDQoIyMDKMV2mM/nMV+OIv9cBb74ax42A9BEOj48eMqKCi46F8I4u5PcImJiRdtTEnKyMi4og+wb7AfzmI/nMV+OIv9cJb1fgiHw5e8D09CAACYoIAAACb6VQGFQiGtWrVKoVDIeimm2A9nsR/OYj+cxX44qz/th7h7EgIA4MrQr86AAAADBwUEADBBAQEATFBAAAAT/aaA1qxZo+9973saPHiwSkpK9Mknn1gvKeaeeuopJSQk9LqMHz/eell9bvv27Zo9e7YKCgqUkJCgTZs29bo9CAI9+eSTys/PV2pqqsrKynTgwAGbxfahS+2HhQsXnnN8zJo1y2axfaSqqko333yz0tPTlZOTozlz5qi2trbXfU6fPq2KigoNGzZMV111lebOnavm5majFfeN77Ifpk2bds7x8PDDDxut+Pz6RQG9/vrrWr58uVatWqVPP/1UxcXFmjlzpo4ePWq9tJi7/vrrdeTIkZ7LRx99ZL2kPtfe3q7i4mKtWbPmvLevXr1azz//vF588UXt3LlTQ4YM0cyZM72GVsazS+0HSZo1a1av4+PVV1+N4Qr7XnV1tSoqKlRTU6P33ntPXV1dmjFjhtrb23vu8+ijj+rtt9/Wm2++qerqajU2Nuree+81XHX0fZf9IEmLFi3qdTysXr3aaMUXEPQDU6ZMCSoqKno+7u7uDgoKCoKqqirDVcXeqlWrguLiYutlmJIUbNy4sefjSCQS5OXlBc8880zPdS0tLUEoFApeffVVgxXGxrf3QxAEwYIFC4K7777bZD1Wjh49GkgKqqurgyA4+71PTk4O3nzzzZ77/Otf/wokBTt27LBaZp/79n4IgiC44447gl/84hd2i/oO4v4MqLOzU7t371ZZWVnPdYmJiSorK9OOHTsMV2bjwIEDKigo0OjRo/XAAw/o0KFD1ksyVV9fr6ampl7HRzgcVklJyRV5fGzbtk05OTkaN26clixZomPHjlkvqU+1trZKkrKysiRJu3fvVldXV6/jYfz48Ro5cuSAPh6+vR++8corryg7O1sTJkxQZWWlTp48abG8C4q7YaTf9tVXX6m7u1u5ubm9rs/NzdXnn39utCobJSUlWr9+vcaNG6cjR47o6aef1u233679+/crPT3denkmmpqaJOm8x8c3t10pZs2apXvvvVdFRUWqq6vTr3/9a5WXl2vHjh1KSkqyXl7URSIRLVu2TLfeeqsmTJgg6ezxkJKSoszMzF73HcjHw/n2gyTdf//9GjVqlAoKCrRv3z6tXLlStbW1euuttwxX21vcFxD+q7y8vOffkyZNUklJiUaNGqU33nhDDz30kOHKEA/mz5/f8++JEydq0qRJGjNmjLZt26bp06cbrqxvVFRUaP/+/VfE46AXc6H9sHjx4p5/T5w4Ufn5+Zo+fbrq6uo0ZsyYWC/zvOL+T3DZ2dlKSko651kszc3NysvLM1pVfMjMzNS1116rgwcPWi/FzDfHAMfHuUaPHq3s7OwBeXwsXbpU77zzjj788MNeb9+Sl5enzs5OtbS09Lr/QD0eLrQfzqekpESS4up4iPsCSklJ0eTJk7V169ae6yKRiLZu3arS0lLDldk7ceKE6urqlJ+fb70UM0VFRcrLy+t1fLS1tWnnzp1X/PFx+PBhHTt2bEAdH0EQaOnSpdq4caM++OADFRUV9bp98uTJSk5O7nU81NbW6tChQwPqeLjUfjifvXv3SlJ8HQ/Wz4L4Ll577bUgFAoF69evDz777LNg8eLFQWZmZtDU1GS9tJj65S9/GWzbti2or68P/vGPfwRlZWVBdnZ2cPToUeul9anjx48He/bsCfbs2RNICp599tlgz549wX/+858gCILgD3/4Q5CZmRls3rw52LdvX3D33XcHRUVFwalTp4xXHl0X2w/Hjx8PVqxYEezYsSOor68P3n///eDGG28Mxo4dG5w+fdp66VGzZMmSIBwOB9u2bQuOHDnSczl58mTPfR5++OFg5MiRwQcffBDs2rUrKC0tDUpLSw1XHX2X2g8HDx4MfvOb3wS7du0K6uvrg82bNwejR48Opk6darzy3vpFAQVBELzwwgvByJEjg5SUlGDKlClBTU2N9ZJibt68eUF+fn6QkpISDB8+PJg3b15w8OBB62X1uQ8//DCQdM5lwYIFQRCcfSr2E088EeTm5gahUCiYPn16UFtba7voPnCx/XDy5MlgxowZwdVXXx0kJycHo0aNChYtWjTgfkk739cvKVi3bl3PfU6dOhX8/Oc/D4YOHRqkpaUF99xzT3DkyBG7RfeBS+2HQ4cOBVOnTg2ysrKCUCgUXHPNNcGvfvWroLW11Xbh38LbMQAATMT9Y0AAgIGJAgIAmKCAAAAmKCAAgAkKCABgggICAJiggAAAJiggAIAJCggAYIICAgCYoIAAACYoIACAif8HMkSFZa9bsukAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image, label = train_data[1]\n",
    "plt.imshow(image.squeeze(), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloaders\n",
    "\n",
    "turns the data into an iterable object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875 313\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 32\n",
    "train_dataloader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "print(len(train_dataloader), len(test_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1, 28, 28]) torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "train_features, train_labels = next(iter(train_dataloader))\n",
    "print(train_features.shape, train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1799416d0>"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "random_idx = torch.randint(0, len(train_features), (1,)).item()\n",
    "img, label = train_features[random_idx], train_labels[random_idx]\n",
    "plt.title(class_names[label]) \n",
    "plt.imshow(img.squeeze(), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 784])"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flatten_model = nn.Flatten()\n",
    "\n",
    "x = train_features[0]\n",
    "\n",
    "op = flatten_model(x)\n",
    "op.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CVModel(\n",
       "  (layer_stack): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(in_features=784, out_features=10, bias=True)\n",
       "    (2): Linear(in_features=10, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class CVModel(nn.Module):\n",
    "    def __init__(self, input_shape, hidden_units, output_shape):\n",
    "        super().__init__()\n",
    "        self.layer_stack = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(input_shape, hidden_units),\n",
    "            nn.Linear(hidden_units, output_shape)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layer_stack(x)\n",
    "\n",
    "model = CVModel(28*28, 10, len(class_names))\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss function, optimizer and evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics import Accuracy\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(params=model.parameters(), lr=0.1)\n",
    "accuracy = Accuracy(task='multiclass', num_classes=len(class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeit import default_timer as timer\n",
    "\n",
    "def print_train_time(start: float, end: float):\n",
    "    total_time = end - start\n",
    "    print(f\"Total Time: {total_time:.3f}s\")\n",
    "    return total_time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "-----\n",
      "Looked at 0/60000 samples\n",
      "Looked at 12800/60000 samples\n",
      "Looked at 25600/60000 samples\n",
      "Looked at 38400/60000 samples\n",
      "Looked at 51200/60000 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [00:04<00:16,  4.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Train Loss: 0.59 | Train Acc: 0.79 | Test Loss: 0.50 | Test Acc: 0.82\n",
      "Epoch: 1\n",
      "-----\n",
      "Looked at 0/60000 samples\n",
      "Looked at 12800/60000 samples\n",
      "Looked at 25600/60000 samples\n",
      "Looked at 38400/60000 samples\n",
      "Looked at 51200/60000 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [00:08<00:13,  4.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Train Loss: 0.48 | Train Acc: 0.83 | Test Loss: 0.48 | Test Acc: 0.83\n",
      "Epoch: 2\n",
      "-----\n",
      "Looked at 0/60000 samples\n",
      "Looked at 12800/60000 samples\n",
      "Looked at 25600/60000 samples\n",
      "Looked at 38400/60000 samples\n",
      "Looked at 51200/60000 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [00:12<00:08,  4.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Train Loss: 0.45 | Train Acc: 0.84 | Test Loss: 0.48 | Test Acc: 0.83\n",
      "Epoch: 3\n",
      "-----\n",
      "Looked at 0/60000 samples\n",
      "Looked at 12800/60000 samples\n",
      "Looked at 25600/60000 samples\n",
      "Looked at 38400/60000 samples\n",
      "Looked at 51200/60000 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [00:17<00:04,  4.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Train Loss: 0.44 | Train Acc: 0.85 | Test Loss: 0.46 | Test Acc: 0.84\n",
      "Epoch: 4\n",
      "-----\n",
      "Looked at 0/60000 samples\n",
      "Looked at 12800/60000 samples\n",
      "Looked at 25600/60000 samples\n",
      "Looked at 38400/60000 samples\n",
      "Looked at 51200/60000 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:21<00:00,  4.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Train Loss: 0.44 | Train Acc: 0.85 | Test Loss: 0.47 | Test Acc: 0.83\n",
      "Total Time: 21.283s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm   # for progress bar\n",
    "\n",
    "torch.manual_seed(42)\n",
    "train_time_start = timer()\n",
    "\n",
    "epochs = 5\n",
    "\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    print(f\"Epoch: {epoch}\\n-----\")\n",
    "    train_loss, train_acc = 0, 0\n",
    "    for batch, (X, y) in enumerate(train_dataloader):\n",
    "        model.train()\n",
    "        y_pred = model(X)\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        train_loss += loss\n",
    "        train_acc += accuracy(y_pred, y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 400 == 0:\n",
    "            print(f\"Looked at {batch * len(X)}/{len(train_dataloader.dataset)} samples\")\n",
    "\n",
    "    train_loss /= len(train_dataloader)  # find average train_loss per batch for that particular epochs\n",
    "    train_acc /= len(train_dataloader)\n",
    "\n",
    "    test_loss, test_acc = 0, 0\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        for X_test, y_test in test_dataloader:\n",
    "            test_pred = model(X_test)\n",
    "            loss = loss_fn(test_pred, y_test)\n",
    "            test_loss +=  loss\n",
    "            test_acc += accuracy(test_pred, y_test)\n",
    "\n",
    "        test_loss /= len(test_dataloader)\n",
    "        test_acc /= len(test_dataloader)\n",
    "\n",
    "    print(f\"\\n Train Loss: {train_loss:.2f} | Train Acc: {train_acc:.2f} | Test Loss: {test_loss:.2f} | Test Acc: {test_acc:.2f}\")\n",
    "\n",
    "train_time_end = timer()\n",
    "\n",
    "total_train_time = print_train_time(train_time_start, train_time_end)\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improving model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CVModelV1(\n",
       "  (layer_stack): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(in_features=784, out_features=10, bias=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=10, out_features=10, bias=True)\n",
       "    (4): ReLU()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class CVModelV1(nn.Module):\n",
    "    def __init__(self, input_shape: int, hidden_units: int, output_shape: int):\n",
    "        super().__init__()\n",
    "        self.layer_stack = nn.Sequential(\n",
    "            nn.Flatten(), # flatten inputs into single vector\n",
    "            nn.Linear(in_features=input_shape, out_features=hidden_units),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=hidden_units, out_features=output_shape),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x: torch.Tensor):\n",
    "        return self.layer_stack(x)\n",
    "    \n",
    "model_1 = CVModelV1(28*28, 10, len(class_names))\n",
    "model_1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(CrossEntropyLoss(),\n",
       " SGD (\n",
       " Parameter Group 0\n",
       "     dampening: 0\n",
       "     differentiable: False\n",
       "     foreach: None\n",
       "     lr: 0.1\n",
       "     maximize: False\n",
       "     momentum: 0\n",
       "     nesterov: False\n",
       "     weight_decay: 0\n",
       " ),\n",
       " MulticlassAccuracy())"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(params=model_1.parameters(), lr=0.1)\n",
    "accuracy = Accuracy(task='multiclass', num_classes=len(class_names))\n",
    "\n",
    "loss_fn, optimizer, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "-----\n",
      "Looked at 0/60000 samples\n",
      "Looked at 12800/60000 samples\n",
      "Looked at 25600/60000 samples\n",
      "Looked at 38400/60000 samples\n",
      "Looked at 51200/60000 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [00:04<00:18,  4.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Train Loss: 1.10 | Train Acc: 0.62 | Test Loss: 0.77 | Test Acc: 0.72\n",
      "Epoch: 1\n",
      "-----\n",
      "Looked at 0/60000 samples\n",
      "Looked at 12800/60000 samples\n",
      "Looked at 25600/60000 samples\n",
      "Looked at 38400/60000 samples\n",
      "Looked at 51200/60000 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [00:08<00:13,  4.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Train Loss: 0.72 | Train Acc: 0.74 | Test Loss: 0.74 | Test Acc: 0.74\n",
      "Epoch: 2\n",
      "-----\n",
      "Looked at 0/60000 samples\n",
      "Looked at 12800/60000 samples\n",
      "Looked at 25600/60000 samples\n",
      "Looked at 38400/60000 samples\n",
      "Looked at 51200/60000 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [00:13<00:08,  4.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Train Loss: 0.67 | Train Acc: 0.75 | Test Loss: 0.69 | Test Acc: 0.75\n",
      "Epoch: 3\n",
      "-----\n",
      "Looked at 0/60000 samples\n",
      "Looked at 12800/60000 samples\n",
      "Looked at 25600/60000 samples\n",
      "Looked at 38400/60000 samples\n",
      "Looked at 51200/60000 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [00:17<00:04,  4.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Train Loss: 0.65 | Train Acc: 0.76 | Test Loss: 0.69 | Test Acc: 0.75\n",
      "Epoch: 4\n",
      "-----\n",
      "Looked at 0/60000 samples\n",
      "Looked at 12800/60000 samples\n",
      "Looked at 25600/60000 samples\n",
      "Looked at 38400/60000 samples\n",
      "Looked at 51200/60000 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:21<00:00,  4.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Train Loss: 0.64 | Train Acc: 0.76 | Test Loss: 0.71 | Test Acc: 0.74\n",
      "Total Time: 21.133s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm   # for progress bar\n",
    "\n",
    "torch.manual_seed(42)\n",
    "train_time_start = timer()\n",
    "\n",
    "epochs = 5\n",
    "\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    print(f\"Epoch: {epoch}\\n-----\")\n",
    "    train_loss, train_acc = 0, 0\n",
    "    for batch, (X, y) in enumerate(train_dataloader):\n",
    "        model_1.train()\n",
    "        y_pred = model_1(X)\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        train_loss += loss\n",
    "        train_acc += accuracy(y_pred, y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 400 == 0:\n",
    "            print(f\"Looked at {batch * len(X)}/{len(train_dataloader.dataset)} samples\")\n",
    "\n",
    "    train_loss /= len(train_dataloader)  # find average train_loss per batch for that particular epochs\n",
    "    train_acc /= len(train_dataloader)\n",
    "\n",
    "    test_loss, test_acc = 0, 0\n",
    "    model_1.eval()\n",
    "    with torch.inference_mode():\n",
    "        for X_test, y_test in test_dataloader:\n",
    "            test_pred = model_1(X_test)\n",
    "            loss = loss_fn(test_pred, y_test)\n",
    "            test_loss += loss\n",
    "            test_acc += accuracy(test_pred, y_test)\n",
    "\n",
    "        test_loss /= len(test_dataloader)\n",
    "        test_acc /= len(test_dataloader)\n",
    "\n",
    "    print(f\"\\n Train Loss: {train_loss:.2f} | Train Acc: {train_acc:.2f} | Test Loss: {test_loss:.2f} | Test Acc: {test_acc:.2f}\")\n",
    "\n",
    "train_time_end = timer()\n",
    "\n",
    "total_train_time = print_train_time(train_time_start, train_time_end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functionizing training and testing loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model, optimizer, loss_fn, accuracy, train_dataloader):\n",
    "    train_loss, train_acc = 0, 0\n",
    "    for batch, (X, y) in enumerate(train_dataloader):\n",
    "        y_pred = model(X)\n",
    "\n",
    "        # 2. Calculate loss\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        train_loss += loss\n",
    "        train_acc += accuracy(y_pred, y) # Go from logits -> pred labels\n",
    "\n",
    "        # 3. Optimizer zero grad\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 4. Loss backward\n",
    "        loss.backward()\n",
    "\n",
    "        # 5. Optimizer step\n",
    "        optimizer.step()\n",
    "\n",
    "    # Calculate loss and accuracy per epoch and print out what's happening\n",
    "    train_loss /= len(train_dataloader)\n",
    "    train_acc /= len(train_dataloader)\n",
    "    print(f\"Train loss: {train_loss:.5f} | Train accuracy: {train_acc:.2f}%\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_step(model, loss_fn, accuracy, test_dataloader):\n",
    "    test_loss, test_acc = 0, 0\n",
    "    model.eval() # put model in eval mode\n",
    "    # Turn on inference context manager\n",
    "    with torch.inference_mode(): \n",
    "        for X, y in train_dataloader:\n",
    "            # Send data to GPU\n",
    "            \n",
    "            # 1. Forward pass\n",
    "            test_pred = model(X)\n",
    "            \n",
    "            # 2. Calculate loss and accuracy\n",
    "            test_loss += loss_fn(test_pred, y)\n",
    "            test_acc += accuracy(y_pred, y) \n",
    "        # Adjust metrics and print out\n",
    "        test_loss /= len(test_dataloader)\n",
    "        test_acc /= len(test_dataloader)\n",
    "        print(f\"Test loss: {test_loss:.5f} | Test accuracy: {test_acc:.2f}%\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(CVModelV1(\n",
       "   (layer_stack): Sequential(\n",
       "     (0): Flatten(start_dim=1, end_dim=-1)\n",
       "     (1): Linear(in_features=784, out_features=10, bias=True)\n",
       "     (2): ReLU()\n",
       "     (3): Linear(in_features=10, out_features=10, bias=True)\n",
       "     (4): ReLU()\n",
       "   )\n",
       " ),\n",
       " SGD (\n",
       " Parameter Group 0\n",
       "     dampening: 0\n",
       "     differentiable: False\n",
       "     foreach: None\n",
       "     lr: 0.1\n",
       "     maximize: False\n",
       "     momentum: 0\n",
       "     nesterov: False\n",
       "     weight_decay: 0\n",
       " ),\n",
       " CrossEntropyLoss(),\n",
       " MulticlassAccuracy())"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "epochs = 5\n",
    "\n",
    "model_2 = CVModelV1(28*28, 10, len(class_names))\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(params=model_2.parameters(), lr=0.1)\n",
    "accuracy = Accuracy(task='multiclass', num_classes=len(class_names))\n",
    "\n",
    "model_2, optimizer, loss_fn, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "-----\n",
      "Train loss: 1.05878 | Train accuracy: 0.62%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [00:06<00:25,  6.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 5.77113 | Test accuracy: 0.62%\n",
      "\n",
      "Epoch: 1\n",
      "-----\n",
      "Train loss: 0.91179 | Train accuracy: 0.66%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [00:12<00:19,  6.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 5.51609 | Test accuracy: 0.60%\n",
      "\n",
      "Epoch: 2\n",
      "-----\n",
      "Train loss: 0.88172 | Train accuracy: 0.67%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [00:19<00:12,  6.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 5.07840 | Test accuracy: 0.60%\n",
      "\n",
      "Epoch: 3\n",
      "-----\n",
      "Train loss: 0.86017 | Train accuracy: 0.68%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [00:26<00:06,  6.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 4.99192 | Test accuracy: 0.60%\n",
      "\n",
      "Epoch: 4\n",
      "-----\n",
      "Train loss: 0.84860 | Train accuracy: 0.68%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:32<00:00,  6.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 4.94769 | Test accuracy: 0.61%\n",
      "\n",
      "Total Time: 32.581s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_time_start = timer()\n",
    "\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    print(f\"Epoch: {epoch}\\n-----\")\n",
    "    train_step(model_2, optimizer, loss_fn, accuracy, train_dataloader)\n",
    "    test_step(model_2, loss_fn, accuracy, test_dataloader)\n",
    "\n",
    "train_time_end = timer()\n",
    "total_train_time = print_train_time(train_time_start, train_time_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(CVModelV1(\n",
       "   (layer_stack): Sequential(\n",
       "     (0): Flatten(start_dim=1, end_dim=-1)\n",
       "     (1): Linear(in_features=784, out_features=10, bias=True)\n",
       "     (2): ReLU()\n",
       "     (3): Linear(in_features=10, out_features=10, bias=True)\n",
       "     (4): ReLU()\n",
       "   )\n",
       " ),\n",
       " SGD (\n",
       " Parameter Group 0\n",
       "     dampening: 0\n",
       "     differentiable: False\n",
       "     foreach: None\n",
       "     lr: 0.1\n",
       "     maximize: False\n",
       "     momentum: 0\n",
       "     nesterov: False\n",
       "     weight_decay: 0\n",
       " ),\n",
       " CrossEntropyLoss(),\n",
       " MulticlassAccuracy())"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "epochs = 5\n",
    "\n",
    "model_3 = CVModelV1(28*28, 10, len(class_names))\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(params=model_3.parameters(), lr=0.1)\n",
    "accuracy = Accuracy(task='multiclass', num_classes=len(class_names))\n",
    "\n",
    "model_3, optimizer, loss_fn, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "-----\n",
      "Looked at 0/60000 samples\n",
      "Looked at 12800/60000 samples\n",
      "Looked at 25600/60000 samples\n",
      "Looked at 38400/60000 samples\n",
      "Looked at 51200/60000 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [00:04<00:17,  4.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Train Loss: 1.09 | Train Acc: 0.61 | Test Loss: 0.96 | Test Acc: 0.65\n",
      "Epoch: 1\n",
      "-----\n",
      "Looked at 0/60000 samples\n",
      "Looked at 12800/60000 samples\n",
      "Looked at 25600/60000 samples\n",
      "Looked at 38400/60000 samples\n",
      "Looked at 51200/60000 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [00:08<00:12,  4.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Train Loss: 0.78 | Train Acc: 0.72 | Test Loss: 0.72 | Test Acc: 0.74\n",
      "Epoch: 2\n",
      "-----\n",
      "Looked at 0/60000 samples\n",
      "Looked at 12800/60000 samples\n",
      "Looked at 25600/60000 samples\n",
      "Looked at 38400/60000 samples\n",
      "Looked at 51200/60000 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [00:12<00:08,  4.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Train Loss: 0.67 | Train Acc: 0.76 | Test Loss: 0.69 | Test Acc: 0.75\n",
      "Epoch: 3\n",
      "-----\n",
      "Looked at 0/60000 samples\n",
      "Looked at 12800/60000 samples\n",
      "Looked at 25600/60000 samples\n",
      "Looked at 38400/60000 samples\n",
      "Looked at 51200/60000 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [00:16<00:04,  4.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Train Loss: 0.64 | Train Acc: 0.77 | Test Loss: 0.65 | Test Acc: 0.76\n",
      "Epoch: 4\n",
      "-----\n",
      "Looked at 0/60000 samples\n",
      "Looked at 12800/60000 samples\n",
      "Looked at 25600/60000 samples\n",
      "Looked at 38400/60000 samples\n",
      "Looked at 51200/60000 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:21<00:00,  4.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Train Loss: 0.63 | Train Acc: 0.77 | Test Loss: 0.65 | Test Acc: 0.76\n",
      "Total Time: 21.198s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm   # for progress bar\n",
    "\n",
    "torch.manual_seed(42)\n",
    "train_time_start = timer()\n",
    "\n",
    "epochs = 5\n",
    "\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    print(f\"Epoch: {epoch}\\n-----\")\n",
    "    train_loss, train_acc = 0, 0\n",
    "    for batch, (X, y) in enumerate(train_dataloader):\n",
    "        model_3.train()\n",
    "        y_pred = model_3(X)\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        train_loss += loss\n",
    "        train_acc += accuracy(y_pred, y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 400 == 0:\n",
    "            print(f\"Looked at {batch * len(X)}/{len(train_dataloader.dataset)} samples\")\n",
    "\n",
    "    train_loss /= len(train_dataloader)  # find average train_loss per batch for that particular epochs\n",
    "    train_acc /= len(train_dataloader)\n",
    "\n",
    "    test_loss, test_acc = 0, 0\n",
    "    model_3.eval()\n",
    "    with torch.inference_mode():\n",
    "        for X_test, y_test in test_dataloader:\n",
    "            test_pred = model_3(X_test)\n",
    "            loss = loss_fn(test_pred, y_test)\n",
    "            test_loss += loss\n",
    "            test_acc += accuracy(test_pred, y_test)\n",
    "\n",
    "        test_loss /= len(test_dataloader)\n",
    "        test_acc /= len(test_dataloader)\n",
    "\n",
    "    print(f\"\\n Train Loss: {train_loss:.2f} | Train Acc: {train_acc:.2f} | Test Loss: {test_loss:.2f} | Test Acc: {test_acc:.2f}\")\n",
    "\n",
    "train_time_end = timer()\n",
    "\n",
    "total_train_time = print_train_time(train_time_start, train_time_end)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
