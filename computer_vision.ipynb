{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries\n",
    "\n",
    "`torchvision.datasets` contains some popular datasets for computer vision.\n",
    "\n",
    "`torchvision.models` contains some popular architectures for computer vision.\n",
    "\n",
    "`torchvision.transforms` contains common image transformations.\n",
    "\n",
    "`torch.utils.data.Dataset` is an abstract class representing a dataset.\n",
    "\n",
    "`torch.utils.data.DataLoader` wraps a dataset and provides access to the underlying data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.1\n",
      "0.15.2\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(torch.__version__)\n",
    "print(torchvision.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "train_data = datasets.FashionMNIST(root=\"data\", train=True, download=True, transform=ToTensor(), target_transform=None)\n",
    "test_data = datasets.FashionMNIST(root=\"data\", train=False, download=True, transform=ToTensor(), target_transform=None)\n",
    "\n",
    "print(len(train_data))\n",
    "print(len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n"
     ]
    }
   ],
   "source": [
    "class_names = train_data.classes\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'T-shirt/top': 0, 'Trouser': 1, 'Pullover': 2, 'Dress': 3, 'Coat': 4, 'Sandal': 5, 'Shirt': 6, 'Sneaker': 7, 'Bag': 8, 'Ankle boot': 9}\n"
     ]
    }
   ],
   "source": [
    "class_to_idx = train_data.class_to_idx\n",
    "print(class_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.0000, 0.0510,\n",
       "           0.2863, 0.0000, 0.0000, 0.0039, 0.0157, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0039, 0.0039, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0118, 0.0000, 0.1412, 0.5333,\n",
       "           0.4980, 0.2431, 0.2118, 0.0000, 0.0000, 0.0000, 0.0039, 0.0118,\n",
       "           0.0157, 0.0000, 0.0000, 0.0118],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0235, 0.0000, 0.4000, 0.8000,\n",
       "           0.6902, 0.5255, 0.5647, 0.4824, 0.0902, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0471, 0.0392, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6078, 0.9255,\n",
       "           0.8118, 0.6980, 0.4196, 0.6118, 0.6314, 0.4275, 0.2510, 0.0902,\n",
       "           0.3020, 0.5098, 0.2824, 0.0588],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.2706, 0.8118, 0.8745,\n",
       "           0.8549, 0.8471, 0.8471, 0.6392, 0.4980, 0.4745, 0.4784, 0.5725,\n",
       "           0.5529, 0.3451, 0.6745, 0.2588],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0039, 0.0039, 0.0039, 0.0000, 0.7843, 0.9098, 0.9098,\n",
       "           0.9137, 0.8980, 0.8745, 0.8745, 0.8431, 0.8353, 0.6431, 0.4980,\n",
       "           0.4824, 0.7686, 0.8980, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7176, 0.8824, 0.8471,\n",
       "           0.8745, 0.8941, 0.9216, 0.8902, 0.8784, 0.8706, 0.8784, 0.8667,\n",
       "           0.8745, 0.9608, 0.6784, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7569, 0.8941, 0.8549,\n",
       "           0.8353, 0.7765, 0.7059, 0.8314, 0.8235, 0.8275, 0.8353, 0.8745,\n",
       "           0.8627, 0.9529, 0.7922, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0039, 0.0118, 0.0000, 0.0471, 0.8588, 0.8627, 0.8314,\n",
       "           0.8549, 0.7529, 0.6627, 0.8902, 0.8157, 0.8549, 0.8784, 0.8314,\n",
       "           0.8863, 0.7725, 0.8196, 0.2039],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0235, 0.0000, 0.3882, 0.9569, 0.8706, 0.8627,\n",
       "           0.8549, 0.7961, 0.7765, 0.8667, 0.8431, 0.8353, 0.8706, 0.8627,\n",
       "           0.9608, 0.4667, 0.6549, 0.2196],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0157, 0.0000, 0.0000, 0.2157, 0.9255, 0.8941, 0.9020,\n",
       "           0.8941, 0.9412, 0.9098, 0.8353, 0.8549, 0.8745, 0.9176, 0.8510,\n",
       "           0.8510, 0.8196, 0.3608, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0039, 0.0157, 0.0235, 0.0275, 0.0078, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.9294, 0.8863, 0.8510, 0.8745,\n",
       "           0.8706, 0.8588, 0.8706, 0.8667, 0.8471, 0.8745, 0.8980, 0.8431,\n",
       "           0.8549, 1.0000, 0.3020, 0.0000],\n",
       "          [0.0000, 0.0118, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.2431, 0.5686, 0.8000, 0.8941, 0.8118, 0.8353, 0.8667,\n",
       "           0.8549, 0.8157, 0.8275, 0.8549, 0.8784, 0.8745, 0.8588, 0.8431,\n",
       "           0.8784, 0.9569, 0.6235, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0706, 0.1725, 0.3216, 0.4196,\n",
       "           0.7412, 0.8941, 0.8627, 0.8706, 0.8510, 0.8863, 0.7843, 0.8039,\n",
       "           0.8275, 0.9020, 0.8784, 0.9176, 0.6902, 0.7373, 0.9804, 0.9725,\n",
       "           0.9137, 0.9333, 0.8431, 0.0000],\n",
       "          [0.0000, 0.2235, 0.7333, 0.8157, 0.8784, 0.8667, 0.8784, 0.8157,\n",
       "           0.8000, 0.8392, 0.8157, 0.8196, 0.7843, 0.6235, 0.9608, 0.7569,\n",
       "           0.8078, 0.8745, 1.0000, 1.0000, 0.8667, 0.9176, 0.8667, 0.8275,\n",
       "           0.8627, 0.9098, 0.9647, 0.0000],\n",
       "          [0.0118, 0.7922, 0.8941, 0.8784, 0.8667, 0.8275, 0.8275, 0.8392,\n",
       "           0.8039, 0.8039, 0.8039, 0.8627, 0.9412, 0.3137, 0.5882, 1.0000,\n",
       "           0.8980, 0.8667, 0.7373, 0.6039, 0.7490, 0.8235, 0.8000, 0.8196,\n",
       "           0.8706, 0.8941, 0.8824, 0.0000],\n",
       "          [0.3843, 0.9137, 0.7765, 0.8235, 0.8706, 0.8980, 0.8980, 0.9176,\n",
       "           0.9765, 0.8627, 0.7608, 0.8431, 0.8510, 0.9451, 0.2549, 0.2863,\n",
       "           0.4157, 0.4588, 0.6588, 0.8588, 0.8667, 0.8431, 0.8510, 0.8745,\n",
       "           0.8745, 0.8784, 0.8980, 0.1137],\n",
       "          [0.2941, 0.8000, 0.8314, 0.8000, 0.7569, 0.8039, 0.8275, 0.8824,\n",
       "           0.8471, 0.7255, 0.7725, 0.8078, 0.7765, 0.8353, 0.9412, 0.7647,\n",
       "           0.8902, 0.9608, 0.9373, 0.8745, 0.8549, 0.8314, 0.8196, 0.8706,\n",
       "           0.8627, 0.8667, 0.9020, 0.2627],\n",
       "          [0.1882, 0.7961, 0.7176, 0.7608, 0.8353, 0.7725, 0.7255, 0.7451,\n",
       "           0.7608, 0.7529, 0.7922, 0.8392, 0.8588, 0.8667, 0.8627, 0.9255,\n",
       "           0.8824, 0.8471, 0.7804, 0.8078, 0.7294, 0.7098, 0.6941, 0.6745,\n",
       "           0.7098, 0.8039, 0.8078, 0.4510],\n",
       "          [0.0000, 0.4784, 0.8588, 0.7569, 0.7020, 0.6706, 0.7176, 0.7686,\n",
       "           0.8000, 0.8235, 0.8353, 0.8118, 0.8275, 0.8235, 0.7843, 0.7686,\n",
       "           0.7608, 0.7490, 0.7647, 0.7490, 0.7765, 0.7529, 0.6902, 0.6118,\n",
       "           0.6549, 0.6941, 0.8235, 0.3608],\n",
       "          [0.0000, 0.0000, 0.2902, 0.7412, 0.8314, 0.7490, 0.6863, 0.6745,\n",
       "           0.6863, 0.7098, 0.7255, 0.7373, 0.7412, 0.7373, 0.7569, 0.7765,\n",
       "           0.8000, 0.8196, 0.8235, 0.8235, 0.8275, 0.7373, 0.7373, 0.7608,\n",
       "           0.7529, 0.8471, 0.6667, 0.0000],\n",
       "          [0.0078, 0.0000, 0.0000, 0.0000, 0.2588, 0.7843, 0.8706, 0.9294,\n",
       "           0.9373, 0.9490, 0.9647, 0.9529, 0.9569, 0.8667, 0.8627, 0.7569,\n",
       "           0.7490, 0.7020, 0.7137, 0.7137, 0.7098, 0.6902, 0.6510, 0.6588,\n",
       "           0.3882, 0.2275, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1569,\n",
       "           0.2392, 0.1725, 0.2824, 0.1608, 0.1373, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000]]]),\n",
       " 9)"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image, label = train_data[0]\n",
    "image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 28, 28]), 9)"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.shape, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x179adabd0>"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image, label = train_data[1]\n",
    "plt.imshow(image.squeeze(), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloaders\n",
    "\n",
    "turns the data into an iterable object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875 313\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 32\n",
    "train_dataloader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "print(len(train_dataloader), len(test_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1, 28, 28]) torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "train_features, train_labels = next(iter(train_dataloader))\n",
    "print(train_features.shape, train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1799ed390>"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "random_idx = torch.randint(0, len(train_features), (1,)).item()\n",
    "img, label = train_features[random_idx], train_labels[random_idx]\n",
    "plt.title(class_names[label]) \n",
    "plt.imshow(img.squeeze(), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 784])"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flatten_model = nn.Flatten()\n",
    "\n",
    "x = train_features[0]\n",
    "\n",
    "op = flatten_model(x)\n",
    "op.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CVModel(\n",
       "  (layer_stack): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(in_features=784, out_features=10, bias=True)\n",
       "    (2): Linear(in_features=10, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class CVModel(nn.Module):\n",
    "    def __init__(self, input_shape, hidden_units, output_shape):\n",
    "        super().__init__()\n",
    "        self.layer_stack = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(input_shape, hidden_units),\n",
    "            nn.Linear(hidden_units, output_shape)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layer_stack(x)\n",
    "\n",
    "model = CVModel(28*28, 10, len(class_names))\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss function, optimizer and evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics import Accuracy\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(params=model.parameters(), lr=0.1)\n",
    "accuracy = Accuracy(task='multiclass', num_classes=len(class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeit import default_timer as timer\n",
    "\n",
    "def print_train_time(start: float, end: float):\n",
    "    total_time = end - start\n",
    "    print(f\"Total Time: {total_time:.3f}s\")\n",
    "    return total_time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "-----\n",
      "Looked at 0/60000 samples\n",
      "Looked at 12800/60000 samples\n",
      "Looked at 25600/60000 samples\n",
      "Looked at 38400/60000 samples\n",
      "Looked at 51200/60000 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [00:04<00:17,  4.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Train Loss: 0.59 | Train Acc: 0.79 | Test Loss: 0.50 | Test Acc: 0.82\n",
      "Epoch: 1\n",
      "-----\n",
      "Looked at 0/60000 samples\n",
      "Looked at 12800/60000 samples\n",
      "Looked at 25600/60000 samples\n",
      "Looked at 38400/60000 samples\n",
      "Looked at 51200/60000 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [00:08<00:12,  4.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Train Loss: 0.48 | Train Acc: 0.83 | Test Loss: 0.48 | Test Acc: 0.83\n",
      "Epoch: 2\n",
      "-----\n",
      "Looked at 0/60000 samples\n",
      "Looked at 12800/60000 samples\n",
      "Looked at 25600/60000 samples\n",
      "Looked at 38400/60000 samples\n",
      "Looked at 51200/60000 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [00:12<00:08,  4.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Train Loss: 0.46 | Train Acc: 0.84 | Test Loss: 0.48 | Test Acc: 0.83\n",
      "Epoch: 3\n",
      "-----\n",
      "Looked at 0/60000 samples\n",
      "Looked at 12800/60000 samples\n",
      "Looked at 25600/60000 samples\n",
      "Looked at 38400/60000 samples\n",
      "Looked at 51200/60000 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [00:17<00:04,  4.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Train Loss: 0.44 | Train Acc: 0.84 | Test Loss: 0.46 | Test Acc: 0.84\n",
      "Epoch: 4\n",
      "-----\n",
      "Looked at 0/60000 samples\n",
      "Looked at 12800/60000 samples\n",
      "Looked at 25600/60000 samples\n",
      "Looked at 38400/60000 samples\n",
      "Looked at 51200/60000 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:21<00:00,  4.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Train Loss: 0.44 | Train Acc: 0.85 | Test Loss: 0.47 | Test Acc: 0.83\n",
      "Total Time: 21.604s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm   # for progress bar\n",
    "\n",
    "torch.manual_seed(42)\n",
    "train_time_start = timer()\n",
    "\n",
    "epochs = 5\n",
    "\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    print(f\"Epoch: {epoch}\\n-----\")\n",
    "    train_loss, train_acc = 0, 0\n",
    "    for batch, (X, y) in enumerate(train_dataloader):\n",
    "        model.train()\n",
    "        y_pred = model(X)\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        train_loss += loss\n",
    "        train_acc += accuracy(y_pred, y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 400 == 0:\n",
    "            print(f\"Looked at {batch * len(X)}/{len(train_dataloader.dataset)} samples\")\n",
    "\n",
    "    train_loss /= len(train_dataloader)  # find average train_loss per batch for that particular epochs\n",
    "    train_acc /= len(train_dataloader)\n",
    "\n",
    "    test_loss, test_acc = 0, 0\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        for X_test, y_test in test_dataloader:\n",
    "            test_pred = model(X_test)\n",
    "            loss = loss_fn(test_pred, y_test)\n",
    "            test_loss +=  loss\n",
    "            test_acc += accuracy(test_pred, y_test)\n",
    "\n",
    "        test_loss /= len(test_dataloader)\n",
    "        test_acc /= len(test_dataloader)\n",
    "\n",
    "    print(f\"\\n Train Loss: {train_loss:.2f} | Train Acc: {train_acc:.2f} | Test Loss: {test_loss:.2f} | Test Acc: {test_acc:.2f}\")\n",
    "\n",
    "train_time_end = timer()\n",
    "\n",
    "total_train_time = print_train_time(train_time_start, train_time_end)\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improving model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CVModelV1(\n",
       "  (layer_stack): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(in_features=784, out_features=10, bias=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=10, out_features=10, bias=True)\n",
       "    (4): ReLU()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class CVModelV1(nn.Module):\n",
    "    def __init__(self, input_shape: int, hidden_units: int, output_shape: int):\n",
    "        super().__init__()\n",
    "        self.layer_stack = nn.Sequential(\n",
    "            nn.Flatten(), # flatten inputs into single vector\n",
    "            nn.Linear(in_features=input_shape, out_features=hidden_units),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=hidden_units, out_features=output_shape),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x: torch.Tensor):\n",
    "        return self.layer_stack(x)\n",
    "    \n",
    "model_1 = CVModelV1(28*28, 10, len(class_names))\n",
    "model_1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(CrossEntropyLoss(),\n",
       " SGD (\n",
       " Parameter Group 0\n",
       "     dampening: 0\n",
       "     differentiable: False\n",
       "     foreach: None\n",
       "     lr: 0.1\n",
       "     maximize: False\n",
       "     momentum: 0\n",
       "     nesterov: False\n",
       "     weight_decay: 0\n",
       " ),\n",
       " MulticlassAccuracy())"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(params=model_1.parameters(), lr=0.1)\n",
    "accuracy = Accuracy(task='multiclass', num_classes=len(class_names))\n",
    "\n",
    "loss_fn, optimizer, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "-----\n",
      "Looked at 0/60000 samples\n",
      "Looked at 12800/60000 samples\n",
      "Looked at 25600/60000 samples\n",
      "Looked at 38400/60000 samples\n",
      "Looked at 51200/60000 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [00:04<00:18,  4.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Train Loss: 1.10 | Train Acc: 0.62 | Test Loss: 0.77 | Test Acc: 0.72\n",
      "Epoch: 1\n",
      "-----\n",
      "Looked at 0/60000 samples\n",
      "Looked at 12800/60000 samples\n",
      "Looked at 25600/60000 samples\n",
      "Looked at 38400/60000 samples\n",
      "Looked at 51200/60000 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [00:08<00:13,  4.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Train Loss: 0.72 | Train Acc: 0.74 | Test Loss: 0.74 | Test Acc: 0.74\n",
      "Epoch: 2\n",
      "-----\n",
      "Looked at 0/60000 samples\n",
      "Looked at 12800/60000 samples\n",
      "Looked at 25600/60000 samples\n",
      "Looked at 38400/60000 samples\n",
      "Looked at 51200/60000 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [00:13<00:08,  4.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Train Loss: 0.67 | Train Acc: 0.75 | Test Loss: 0.69 | Test Acc: 0.75\n",
      "Epoch: 3\n",
      "-----\n",
      "Looked at 0/60000 samples\n",
      "Looked at 12800/60000 samples\n",
      "Looked at 25600/60000 samples\n",
      "Looked at 38400/60000 samples\n",
      "Looked at 51200/60000 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [00:17<00:04,  4.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Train Loss: 0.65 | Train Acc: 0.76 | Test Loss: 0.69 | Test Acc: 0.75\n",
      "Epoch: 4\n",
      "-----\n",
      "Looked at 0/60000 samples\n",
      "Looked at 12800/60000 samples\n",
      "Looked at 25600/60000 samples\n",
      "Looked at 38400/60000 samples\n",
      "Looked at 51200/60000 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:22<00:00,  4.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Train Loss: 0.64 | Train Acc: 0.76 | Test Loss: 0.71 | Test Acc: 0.74\n",
      "Total Time: 22.009s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm   # for progress bar\n",
    "\n",
    "torch.manual_seed(42)\n",
    "train_time_start = timer()\n",
    "\n",
    "epochs = 5\n",
    "\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    print(f\"Epoch: {epoch}\\n-----\")\n",
    "    train_loss, train_acc = 0, 0\n",
    "    for batch, (X, y) in enumerate(train_dataloader):\n",
    "        model_1.train()\n",
    "        y_pred = model_1(X)\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        train_loss += loss\n",
    "        train_acc += accuracy(y_pred, y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 400 == 0:\n",
    "            print(f\"Looked at {batch * len(X)}/{len(train_dataloader.dataset)} samples\")\n",
    "\n",
    "    train_loss /= len(train_dataloader)  # find average train_loss per batch for that particular epochs\n",
    "    train_acc /= len(train_dataloader)\n",
    "\n",
    "    test_loss, test_acc = 0, 0\n",
    "    model_1.eval()\n",
    "    with torch.inference_mode():\n",
    "        for X_test, y_test in test_dataloader:\n",
    "            test_pred = model_1(X_test)\n",
    "            loss = loss_fn(test_pred, y_test)\n",
    "            test_loss += loss\n",
    "            test_acc += accuracy(test_pred, y_test)\n",
    "\n",
    "        test_loss /= len(test_dataloader)\n",
    "        test_acc /= len(test_dataloader)\n",
    "\n",
    "    print(f\"\\n Train Loss: {train_loss:.2f} | Train Acc: {train_acc:.2f} | Test Loss: {test_loss:.2f} | Test Acc: {test_acc:.2f}\")\n",
    "\n",
    "train_time_end = timer()\n",
    "\n",
    "total_train_time = print_train_time(train_time_start, train_time_end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functionizing training and testing loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model, optimizer, loss_fn, accuracy, train_dataloader):\n",
    "    train_loss, train_acc = 0, 0\n",
    "    for batch, (X, y) in enumerate(train_dataloader):\n",
    "        model.train()\n",
    "        y_pred = model(X)\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        train_loss += loss\n",
    "        train_acc += accuracy(y_pred, y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 400 == 0:\n",
    "            print(f\"Looked at {batch * len(X)}/{len(train_dataloader.dataset)} samples\")\n",
    "\n",
    "    train_loss /= len(train_dataloader)  # find average train_loss per batch for that particular epochs\n",
    "    train_acc /= len(train_dataloader)\n",
    "\n",
    "    print(f\"\\n Train Loss: {train_loss:.2f} | Train Acc: {train_acc:.2f}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_step(model, loss_fn, accuracy, test_dataloader):\n",
    "    test_loss, test_acc = 0, 0\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        for X_test, y_test in test_dataloader:\n",
    "            test_pred = model(X_test)\n",
    "            loss = loss_fn(test_pred, y_test)\n",
    "            test_loss += loss\n",
    "            test_acc += accuracy(test_pred, y_test)\n",
    "\n",
    "        test_loss /= len(test_dataloader)\n",
    "        test_acc /= len(test_dataloader)\n",
    "\n",
    "    print(f\"\\n Test Loss: {test_loss:.2f} | Test Acc: {test_acc:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(CVModelV1(\n",
       "   (layer_stack): Sequential(\n",
       "     (0): Flatten(start_dim=1, end_dim=-1)\n",
       "     (1): Linear(in_features=784, out_features=10, bias=True)\n",
       "     (2): ReLU()\n",
       "     (3): Linear(in_features=10, out_features=10, bias=True)\n",
       "     (4): ReLU()\n",
       "   )\n",
       " ),\n",
       " SGD (\n",
       " Parameter Group 0\n",
       "     dampening: 0\n",
       "     differentiable: False\n",
       "     foreach: None\n",
       "     lr: 0.1\n",
       "     maximize: False\n",
       "     momentum: 0\n",
       "     nesterov: False\n",
       "     weight_decay: 0\n",
       " ),\n",
       " CrossEntropyLoss(),\n",
       " MulticlassAccuracy())"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "epochs = 5\n",
    "\n",
    "model_2 = CVModelV1(28*28, 10, len(class_names))\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(params=model_2.parameters(), lr=0.1)\n",
    "accuracy = Accuracy(task='multiclass', num_classes=len(class_names))\n",
    "\n",
    "model_2, optimizer, loss_fn, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "-----\n",
      "Looked at 0/60000 samples\n",
      "Looked at 12800/60000 samples\n",
      "Looked at 25600/60000 samples\n",
      "Looked at 38400/60000 samples\n",
      "Looked at 51200/60000 samples\n",
      "\n",
      " Train Loss: 1.06 | Train Acc: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [00:04<00:16,  4.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Test Loss: 1.00 | Test Acc: 0.64\n",
      "Epoch: 1\n",
      "-----\n",
      "Looked at 0/60000 samples\n",
      "Looked at 12800/60000 samples\n",
      "Looked at 25600/60000 samples\n",
      "Looked at 38400/60000 samples\n",
      "Looked at 51200/60000 samples\n",
      "\n",
      " Train Loss: 0.91 | Train Acc: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [00:08<00:12,  4.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Test Loss: 0.91 | Test Acc: 0.67\n",
      "Epoch: 2\n",
      "-----\n",
      "Looked at 0/60000 samples\n",
      "Looked at 12800/60000 samples\n",
      "Looked at 25600/60000 samples\n",
      "Looked at 38400/60000 samples\n",
      "Looked at 51200/60000 samples\n",
      "\n",
      " Train Loss: 0.88 | Train Acc: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [00:13<00:08,  4.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Test Loss: 0.89 | Test Acc: 0.66\n",
      "Epoch: 3\n",
      "-----\n",
      "Looked at 0/60000 samples\n",
      "Looked at 12800/60000 samples\n",
      "Looked at 25600/60000 samples\n",
      "Looked at 38400/60000 samples\n",
      "Looked at 51200/60000 samples\n",
      "\n",
      " Train Loss: 0.86 | Train Acc: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [00:17<00:04,  4.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Test Loss: 0.91 | Test Acc: 0.66\n",
      "Epoch: 4\n",
      "-----\n",
      "Looked at 0/60000 samples\n",
      "Looked at 12800/60000 samples\n",
      "Looked at 25600/60000 samples\n",
      "Looked at 38400/60000 samples\n",
      "Looked at 51200/60000 samples\n",
      "\n",
      " Train Loss: 0.85 | Train Acc: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:21<00:00,  4.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Test Loss: 0.87 | Test Acc: 0.67\n",
      "Total Time: 21.415s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_time_start = timer()\n",
    "\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    print(f\"Epoch: {epoch}\\n-----\")\n",
    "    train_step(model_2, optimizer, loss_fn, accuracy, train_dataloader)\n",
    "    test_step(model_2, loss_fn, accuracy, test_dataloader)\n",
    "\n",
    "train_time_end = timer()\n",
    "total_train_time = print_train_time(train_time_start, train_time_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(CVModelV1(\n",
       "   (layer_stack): Sequential(\n",
       "     (0): Flatten(start_dim=1, end_dim=-1)\n",
       "     (1): Linear(in_features=784, out_features=10, bias=True)\n",
       "     (2): ReLU()\n",
       "     (3): Linear(in_features=10, out_features=10, bias=True)\n",
       "     (4): ReLU()\n",
       "   )\n",
       " ),\n",
       " SGD (\n",
       " Parameter Group 0\n",
       "     dampening: 0\n",
       "     differentiable: False\n",
       "     foreach: None\n",
       "     lr: 0.1\n",
       "     maximize: False\n",
       "     momentum: 0\n",
       "     nesterov: False\n",
       "     weight_decay: 0\n",
       " ),\n",
       " CrossEntropyLoss(),\n",
       " MulticlassAccuracy())"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "epochs = 5\n",
    "\n",
    "model_2 = CVModelV1(28*28, 10, len(class_names))\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(params=model_2.parameters(), lr=0.1)\n",
    "accuracy = Accuracy(task='multiclass', num_classes=len(class_names))\n",
    "\n",
    "model_2, optimizer, loss_fn, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "-----\n",
      "Looked at 0/60000 samples\n",
      "Looked at 12800/60000 samples\n",
      "Looked at 25600/60000 samples\n",
      "Looked at 38400/60000 samples\n",
      "Looked at 51200/60000 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [00:04<00:16,  4.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Train Loss: 1.09 | Train Acc: 0.61 | Test Loss: 0.96 | Test Acc: 0.65\n",
      "Epoch: 1\n",
      "-----\n",
      "Looked at 0/60000 samples\n",
      "Looked at 12800/60000 samples\n",
      "Looked at 25600/60000 samples\n",
      "Looked at 38400/60000 samples\n",
      "Looked at 51200/60000 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [00:08<00:12,  4.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Train Loss: 0.78 | Train Acc: 0.72 | Test Loss: 0.72 | Test Acc: 0.74\n",
      "Epoch: 2\n",
      "-----\n",
      "Looked at 0/60000 samples\n",
      "Looked at 12800/60000 samples\n",
      "Looked at 25600/60000 samples\n",
      "Looked at 38400/60000 samples\n",
      "Looked at 51200/60000 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [00:12<00:08,  4.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Train Loss: 0.67 | Train Acc: 0.76 | Test Loss: 0.69 | Test Acc: 0.75\n",
      "Epoch: 3\n",
      "-----\n",
      "Looked at 0/60000 samples\n",
      "Looked at 12800/60000 samples\n",
      "Looked at 25600/60000 samples\n",
      "Looked at 38400/60000 samples\n",
      "Looked at 51200/60000 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [00:16<00:04,  4.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Train Loss: 0.64 | Train Acc: 0.77 | Test Loss: 0.65 | Test Acc: 0.76\n",
      "Epoch: 4\n",
      "-----\n",
      "Looked at 0/60000 samples\n",
      "Looked at 12800/60000 samples\n",
      "Looked at 25600/60000 samples\n",
      "Looked at 38400/60000 samples\n",
      "Looked at 51200/60000 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:21<00:00,  4.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Train Loss: 0.63 | Train Acc: 0.77 | Test Loss: 0.65 | Test Acc: 0.76\n",
      "Total Time: 21.049s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm   # for progress bar\n",
    "\n",
    "torch.manual_seed(42)\n",
    "train_time_start = timer()\n",
    "\n",
    "epochs = 5\n",
    "\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    print(f\"Epoch: {epoch}\\n-----\")\n",
    "    train_loss, train_acc = 0, 0\n",
    "    for batch, (X, y) in enumerate(train_dataloader):\n",
    "        model_2.train()\n",
    "        y_pred = model_2(X)\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        train_loss += loss\n",
    "        train_acc += accuracy(y_pred, y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 400 == 0:\n",
    "            print(f\"Looked at {batch * len(X)}/{len(train_dataloader.dataset)} samples\")\n",
    "\n",
    "    train_loss /= len(train_dataloader)  # find average train_loss per batch for that particular epochs\n",
    "    train_acc /= len(train_dataloader)\n",
    "\n",
    "    test_loss, test_acc = 0, 0\n",
    "    model_2.eval()\n",
    "    with torch.inference_mode():\n",
    "        for X_test, y_test in test_dataloader:\n",
    "            test_pred = model_2(X_test)\n",
    "            loss = loss_fn(test_pred, y_test)\n",
    "            test_loss += loss\n",
    "            test_acc += accuracy(test_pred, y_test)\n",
    "\n",
    "        test_loss /= len(test_dataloader)\n",
    "        test_acc /= len(test_dataloader)\n",
    "\n",
    "    print(f\"\\n Train Loss: {train_loss:.2f} | Train Acc: {train_acc:.2f} | Test Loss: {test_loss:.2f} | Test Acc: {test_acc:.2f}\")\n",
    "\n",
    "train_time_end = timer()\n",
    "\n",
    "total_train_time = print_train_time(train_time_start, train_time_end)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
